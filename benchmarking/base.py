import abc
import dataclasses
from typing import Any, TypedDict
from tasks import FileFormats, TaskTypes


@dataclasses.dataclass
class BenchmarkingResultBase(TypedDict):
    """A base class for benchmarking results.

    1. model: The name of the model used for benchmarking.
    2. file_format: The file format used for benchmarking.
    3. task_type: The type of task being benchmarked.
    4. latency_seconds: The latency of the benchmarking process in seconds.
    5. size_in_bytes: The size of the response in bytes.
    6. prompt_tokens: The number of prompt tokens used for benchmarking.
    7. completion_tokens: The number of completion tokens used for benchmarking.
    8. total_tokens: The total number of tokens used for benchmarking.
    9. response: The response generated by the model.
    10. cost_in_usd: The cost incurred by the model.
    """

    model: str
    file_format: str
    task_type: str
    latency_seconds: float
    size_in_bytes: int
    prompt_tokens: int
    completion_tokens: int
    total_tokens: int
    response: str
    cost_in_usd: float


class BenchmarkingToolBase(abc.ABC):
    """A base class for all benchmarking tools."""

    @abc.abstractmethod
    def call_llm_and_format_response(
        self, model: str, prompt: str, task_type: TaskTypes, file_format: FileFormats
    ) -> BenchmarkingResultBase | None:
        """Calls the respective LLM model with the prompt and returns the response metadata"""
        pass

    @abc.abstractmethod
    def run_benchmarking_on_models(
        self, task_type: TaskTypes, file_format: FileFormats, **kwargs
    ) -> list[BenchmarkingResultBase]:
        """Run benchmarking on a list of models for a given task.

        Args:
            task_type: The type of task to benchmark.
            file_format: The file format to use for the task.
            **kwargs: Additional keyword arguments to pass to the prompt builder.
        """
        pass


class BenchmarkingToolResultExporter(abc.ABC):
    """Base class for exporting benchmarking results for a model"""

    @abc.abstractmethod
    def export_to_csv(
        self, results: list[BenchmarkingResultBase], filename: str
    ) -> None:
        """Export the benchmarking results to a CSV file

        Args:
            results: The list of results to export to CSV
            filename: The name of the file to export to.
        """
        pass
